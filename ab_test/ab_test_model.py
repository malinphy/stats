# -*- coding: utf-8 -*-
"""ab_test_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nzWerZ7qf4O0TnGAqkCcX1Qa4hZ9b2Mm
"""

import numpy as np
import pandas as pd 
import statsmodels.stats.api as sms
import scipy.stats as scs
import matplotlib.pyplot as plt
plt.style.use('ggplot')

#import data
raw_data = pd.read_csv("https://raw.githubusercontent.com/malinphy/datasets/main/ab_testing/ab_data.csv")
df = raw_data.copy()

print("Number of rows: ", df.shape[0], " Number of columns: ", df.shape[1])
df.head()

print(df['group'].value_counts())
print(df['landing_page'].value_counts())
# print(df['converted'].value_counts())

## as seen from the group and the landing page number both numbers are different than each other. This means some data points are duplicated.

# df[df['group'] == 'control'] 
# pd.Index(df.loc[(df['group'] == 'control') & (df['landing_page'] == 'new_page')])

d1 = df.loc[(df['group'] == 'treatment') & (df['landing_page'] == 'old_page')]
d2 = df.loc[(df['group'] == 'control') & (df['landing_page'] == 'new_page')]
d1.index

df = df.drop(d1.index)
df = df.drop(d2.index)

#some of the control group saw the new_page and some tretment group saw the old_page - delete these instances
mask1 = (df["group"] == "control") & (df["landing_page"] == "new_page")
index_to_drop1 = df[mask1].index
df = df.drop(index_to_drop1)

mask2 = (df["group"] == "treatment") & (df["landing_page"] == "old_page")
index_to_drop2 = df[mask2].index
df = df.drop(index_to_drop2)

print(df.shape)
df["group"].value_counts()

#drop duplicated users
df.drop_duplicates(subset ='user_id',keep ='first',inplace = True)
df.head(3)

converted_control_num = df[df['group'] == 'control'].groupby(['converted'])['group'].count()[1]
converted_treatment_num  = df[df['group'] == 'treatment'].groupby(['converted'])['group'].count()[1]

control_num = len(df[df['group'] == 'control'])
treatment_num = len(df[df['group'] == 'treatment'])

print('total_control_count :',control_num)
print('total_treatment_count :',treatment_num)

print('converted_control_count :',converted_control_num)
print('converted_treatment_count :',converted_treatment_num)

def prop(conversion, total):
    return conversion/total

def standard_error(prob, total):
    return  np.sqrt(prob * (1-prob)) / np.sqrt(total)

control_conversion_prop = prop(converted_control_num,control_num)
treatment_conversion_prop = prop(converted_treatment_num,treatment_num)
total_conversion_prop = prop((converted_control_num + converted_treatment_num), (control_num+treatment_num))

control_error = standard_error(control_conversion_prop,control_num)
treatment_error = standard_error(treatment_conversion_prop,treatment_num)


print('control_conversion_proportion :', control_conversion_prop)
print('treatment_conversion_proportion :', treatment_conversion_prop)
print('total_conversion_proportion :', total_conversion_prop)

print('treatment_standard_error :', treatment_error)
print('control_standard_error :', control_error)

x = np.linspace(0.114, .125, 1000)
yt = scs.norm(treatment_conversion_prop, treatment_error).pdf(x)
plt.plot(x, yt, '-.',label='treatment')
plt.axvline(x=treatment_conversion_prop, c='red', alpha=0.5)
plt.legend()

x = np.linspace(0.114, .125, 1000)
yc = scs.norm(control_conversion_prop, control_error).pdf(x)
plt.plot(x, yc,'--',label='control')
plt.axvline(x=control_conversion_prop, c='blue', alpha=0.5)
plt.legend()

plt.xlabel('Converted Proportion')
plt.ylabel('PDF')

d_hat = treatment_conversion_prop - control_conversion_prop

print('d_hat(minimum_detectable_error)',d_hat)

z_score = abs((treatment_conversion_prop - control_conversion_prop))/np.sqrt(total_conversion_prop*(1-total_conversion_prop)*(1/control_num + 1/treatment_num))
print(z_score)

alpha = 0.05
z_critical = 1.96 ### according to critical  alpha for two tailed test
#### after that point if z_score falls in rejection region and rejection region is higher than the z_critical_value

if z_score > z_critical :
    print('null hypothesis cannot be rejected becase z_score is higher that z_critical value')

if z_score < z_critical :
    print('null hypothesis can be rejected becase z_score is lower that z_critical value')

"""n =$\frac{2p_{total}(1 - p_{total})(Z_{β}+Z_{α/2})^2}{(p_b-p_a)^2}$ 
where $p_{total}$ is total conversion proportion 
$p_a$ is treatment proportion 
$p_b$ is control proportion
$Z_{β}$ is level of statistical power 
$Z_{α/2}$ is z score that corresponds to the level significance  or confidence level
"""

# # Z value from z table for 80% is 0.84
# z_beta = 0.84
# z_beta = 1.28
# # z_beta = 0.
((2*total_conversion_prop)*(1- total_conversion_prop)*(z_critical + z_beta)**2)/(treatment_conversion_prop - control_conversion_prop)**2

